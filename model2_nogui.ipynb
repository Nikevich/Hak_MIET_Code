{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#just fallback values\n",
    "LENGTH=20\n",
    "WIDTH=1920\n",
    "HEIGHT=1080\n",
    "FRAMERATE=30\n",
    "color_purple = (255,0,255)\n",
    "color_white = (255,255,255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class TrackedVehicle:\n",
    "    def __init__(self, label, speed,time):\n",
    "        self.label = label\n",
    "        self.speed = speed\n",
    "        self.time = time\n",
    "\n",
    "class TrackableVehicle:\n",
    "    def __init__(self, id: int,\n",
    "                  entered_timestamp: float | None,\n",
    "                  last_anchor, label, indim) -> None:\n",
    "        self.id = id\n",
    "        self.enter_timestamp = entered_timestamp\n",
    "        self.last_anchor = list()\n",
    "        self.last_anchor.append((int(last_anchor[0]),int(last_anchor[1])))\n",
    "        self.labels = dict()\n",
    "        self.labels[label] = 1\n",
    "        self.indims = indim\n",
    "\n",
    "\n",
    "    def label(self):\n",
    "        return max(self.labels, key=self.labels.get)\n",
    "\n",
    "\n",
    "    def finish(self, time):\n",
    "        return TrackedVehicle(self.label(),LENGTH/(time-self.enter_timestamp),time-self.enter_timestamp if self.enter_timestamp is not None else 0)\n",
    "    \n",
    "    def update(self, label, anchor, isins):\n",
    "        if label not in self.labels.keys():\n",
    "            self.labels[label] = 1\n",
    "        else:\n",
    "            self.labels[label] +=1\n",
    "        self.indim=isins\n",
    "\n",
    "    def old_anchor(self):\n",
    "        return self.last_anchor[0]\n",
    "\n",
    "def avspeed(tracked):\n",
    "    n = 0\n",
    "    sp = 0\n",
    "    for v in tracked:\n",
    "        if v.time>=0.4: \n",
    "            sp+=v.speed\n",
    "            n+=1\n",
    "    if n==0: return \"NaN\"\n",
    "    return (sp/n)*3.6\n",
    "\n",
    "def check_in(x, y, poly):\n",
    "    return Polygon(poly).contains(Point(x,y))\n",
    "\n",
    "def in_any(x, y, polys):\n",
    "    for poly in polys:\n",
    "        if Polygon(poly).contains(Point(x,y)): return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8s summary (fused): 168 layers, 11156544 parameters, 0 gradients, 28.6 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "import json\n",
    "import torch\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.jit.enable_onednn_fusion(True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "model.to('cuda')\n",
    "model.fuse()\n",
    "model.compile()\n",
    "\n",
    "\n",
    "#markup = r\"videos/dataset/markup/jsons/KRA-8-28-2023-08-18-morning.json\"\n",
    "#video_path = r\"videos/dataset/Video1/KRA-8-28-2023-08-18-morning.mp4\"\n",
    "\n",
    "\n",
    "def process_video(video_path, markup):\n",
    "    with open(markup, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    zones = data['zones']\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    WIDTH=cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    HEIGHT=cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    FRAMERATE=cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    dims = []\n",
    "    for i, arr in enumerate(zones):\n",
    "        dims.append([])\n",
    "        for j, arr2 in enumerate(arr):\n",
    "            dims[i].append((int(WIDTH*arr2[0]),int(HEIGHT*arr2[1])))\n",
    "\n",
    "    areas = data['areas']\n",
    "\n",
    "    bdims = []\n",
    "    for i, arr in enumerate(areas):\n",
    "        bdims.append([])\n",
    "        for j, arr2 in enumerate(arr):\n",
    "            bdims[i].append((int(WIDTH*arr2[0]),int(HEIGHT*arr2[1])))\n",
    "\n",
    "    # Store the track history\n",
    "    track_history = defaultdict(lambda: [])\n",
    "\n",
    "    needed_classes=[2,3,5,7]\n",
    "\n",
    "    tracking=dict()\n",
    "    tracked=dict()\n",
    "\n",
    "    count=0\n",
    "    # Loop through the video frames\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "        if success:\n",
    "            # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "            results = model.track(frame, persist=True, tracker='bytetrack.yaml', classes=needed_classes, verbose=False)\n",
    "\n",
    "            # Get the boxes and track IDs\n",
    "            tracks = results[0].boxes.cpu()\n",
    "            boxes = results[0].boxes.xywh.cpu()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist() if results[0].boxes.id != None else []\n",
    "\n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "\n",
    "            # Plot the tracks\n",
    "            for box, track_id in zip(boxes, track_ids):\n",
    "                x, y, w, h = box\n",
    "                track = track_history[track_id]\n",
    "                track.append((float(x), float(y+h/2)))  # x, y center point\n",
    "                if len(track) > 90:  # retain 90 tracks for 90 frames\n",
    "                    track.pop(0)\n",
    "\n",
    "                # Draw the tracking lines\n",
    "                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "            \n",
    "            \n",
    "            for box, id, track in zip(boxes, track_ids, tracks):\n",
    "                x,y,w,h = box\n",
    "                isin = in_any(float(x), float(y+h/2), bdims)\n",
    "                isins = in_any(float(x), float(y+h/2), dims)\n",
    "                if isin: \n",
    "                    cv2.circle(annotated_frame, tuple((int(x), int(y+h/2))), 10, (255,0,0), 10)\n",
    "                if ((id not in tracking.keys()) and isin and isins) or (id in tracking.keys() and (not isin)):\n",
    "\n",
    "\n",
    "                    if id not in tracking.keys(): tracking[id] = TrackableVehicle(id,None,(int(x), int(y+h/2)),track.cls,isins)\n",
    "                    \n",
    "                    if isin and isins:\n",
    "                        tracking[id].enter_timestamp = (1/FRAMERATE)*count\n",
    "\n",
    "                    elif (not isin) and tracking[id].indims != isins:\n",
    "                        if (1/FRAMERATE)*count!=tracking[id].enter_timestamp:\n",
    "                            tracked[tracking[id].label()] = tracking[id].finish((1/FRAMERATE)*count)\n",
    "                            tracking.pop(id)\n",
    "                    \n",
    "                if id in tracking.keys(): tracking[id].update(track.cls, (int(x), int(y+h/2)), isins)\n",
    "\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "\n",
    "        count+=1\n",
    "        \n",
    "    # Release the video capture object and close the display window\n",
    "    cap.release()\n",
    "\n",
    "    speeds=dict()\n",
    "    speeds[2]=list()\n",
    "    speeds[3]=list()\n",
    "    speeds[5]=list()\n",
    "    speeds[7]=list()\n",
    "    for track in tracked.values():\n",
    "        if track.time>=0.35: speeds[int(track.label)].append(track.speed)\n",
    "    for k, l in speeds.items():\n",
    "        print(f\"label {k}: \", (sum(l)/len(l))*3.6 if len(l)!=0 else 0)\n",
    "    for k, l in speeds.items():\n",
    "        print(f\"{k}: \", len(l))\n",
    "\n",
    "    return [(sum(l)/len(l))*3.6 if len(l)!=0 else 0 for k,l in speeds.items()], [len(l) for k, l in speeds.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "def find_mp4(directory):\n",
    "    \"\"\"\n",
    "    Recursively search for .mp4 files in a directory and its subdirectories.\n",
    "    \n",
    "    Returns a list of file paths.\n",
    "    \"\"\"\n",
    "    mp4_files = []\n",
    "    for path in pathlib.Path(directory).rglob('*.mp4'):\n",
    "        mp4_files.append(path)\n",
    "    return mp4_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name;quantity_car;average_speed_car;quantity_van;average_speed_van;quantity_bus;average_speed_bus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file_name;quantity_car;average_speed_car;quantity_van;average_speed_van;quantity_bus;average_speed_bus]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv = pd.read_csv(\"submission.csv\")\n",
    "df = csv.head(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [14:19<23:37:41, 859.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 2:  32.76295519059939\n",
      "label 3:  0\n",
      "label 5:  22.989130434782883\n",
      "label 7:  25.11816617384253\n",
      "2:  590\n",
      "3:  0\n",
      "5:  2\n",
      "7:  69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [27:29<22:17:22, 818.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 2:  51.62888646577882\n",
      "label 3:  0\n",
      "label 5:  45.41231884057819\n",
      "label 7:  47.243881725537676\n",
      "2:  422\n",
      "3:  0\n",
      "5:  4\n",
      "7:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [43:31<23:49:36, 884.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 2:  23.65558424470924\n",
      "label 3:  0\n",
      "label 5:  22.313200981774404\n",
      "label 7:  24.92530389672982\n",
      "2:  662\n",
      "3:  0\n",
      "5:  12\n",
      "7:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [58:27<23:41:44, 888.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 2:  31.00087153046881\n",
      "label 3:  0\n",
      "label 5:  28.6605591699457\n",
      "label 7:  43.27855576281764\n",
      "2:  301\n",
      "3:  0\n",
      "5:  10\n",
      "7:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [1:10:53<22:05:41, 837.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 2:  58.61391825396593\n",
      "label 3:  0\n",
      "label 5:  48.490767867117405\n",
      "label 7:  56.47763829032704\n",
      "2:  590\n",
      "3:  0\n",
      "5:  10\n",
      "7:  89\n"
     ]
    }
   ],
   "source": [
    "data_path=r\"videos/dataset/Test_Newest_2\"\n",
    "markup_path=r\"videos/dataset/Test_markup\"\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_mp4=find_mp4(data_path)\n",
    "ids=[]\n",
    "result=[]\n",
    "for file in tqdm(data_mp4):\n",
    "    json_path = markup_path+\"/\"+file.stem+\".json\"\n",
    "    result.append(process_video(str(file), json_path))\n",
    "    ids.append(file.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
