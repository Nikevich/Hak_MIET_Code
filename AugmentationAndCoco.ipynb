{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6deb3-5765-43b8-91b5-5f1f7e46c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "#print(HOME)\n",
    "%cd {HOME}\n",
    "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
    "%cd {HOME}/GroundingDINO\n",
    "%pip install datumaro\n",
    "%pip install -r requirements.txt\n",
    "%pip install -q -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e110edda-593d-4d4d-92d4-21d7c03a7448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CONFIG_PATH = os.path.join(HOME, \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\")\n",
    "print(CONFIG_PATH, \"; exist:\", os.path.isfile(CONFIG_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f86ea3-4fb4-4e4b-94ae-bcad0b0f7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorrt --extra-index-url https://pypi.nvidia.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5523ecc-1215-489f-bb96-d2d1ae2c3a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "print(HOME)\n",
    "%cd {HOME}/weights\n",
    "\n",
    "!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82209663-c8f0-4f63-8361-4cab6deaec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "WEIGHTS_NAME = \"groundingdino_swint_ogc.pth\"\n",
    "WEIGHTS_PATH = os.path.join(HOME, \"weights\", WEIGHTS_NAME)\n",
    "print(WEIGHTS_PATH, \"; exist:\", os.path.isfile(WEIGHTS_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c0e510-d9e7-4ec6-a418-e5e090f0388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/jupyter/datasphere/project/GroundingDINO\n",
    "\n",
    "from groundingdino.util.inference import Model, load_model, load_image, annotate\n",
    "\n",
    "model = Model(model_config_path=CONFIG_PATH, model_checkpoint_path=WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef510feb-cd8e-4e18-a1d2-b3bd09fe3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import supervision as sv\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "from datumaro import Polygon, Bbox, RleMask, Dataset, DatasetItem, Image\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "images = []\n",
    "frame_path = \"/home/jupyter/datasphere/project/datata/Frames\"\n",
    "\n",
    "for _,_,files in os.walk(frame_path):\n",
    "    images = files\n",
    "\n",
    "for i,im in enumerate(images):\n",
    "    images[i] = frame_path + \"/\" + im \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "results = []\n",
    "for image_name in tqdm(images):\n",
    "    image_path = os.path.join(HOME, \"data\", image_name)\n",
    "\n",
    "    CLASSES = [\"car\",\"bus\",\"truck\"]\n",
    "    BOX_TRESHOLD = 0.35\n",
    "    TEXT_TRESHOLD = 0.25\n",
    "\n",
    "\n",
    "    image = cv2.imread(image_name)\n",
    "\n",
    "    detections = model.predict_with_classes(\n",
    "        image=image,\n",
    "        classes=CLASSES,\n",
    "        box_threshold=BOX_TRESHOLD,\n",
    "        text_threshold=TEXT_TRESHOLD\n",
    "    )\n",
    "    boxes = detections.xyxy\n",
    "    \n",
    "    \n",
    "    \n",
    "    box_annotator = sv.BoxAnnotator()\n",
    "    labels = [\n",
    "        f\"{CLASSES[class_id]} {confidence:0.2f}\" \n",
    "        for _, _, confidence, class_id,_ in detections]\n",
    "    annotated_frame = box_annotator.annotate(scene=image.copy(), detections=detections, labels=labels)\n",
    "\n",
    "    #matplotlib inline\n",
    "    #sv.plot_image(annotated_frame, (16, 16))\n",
    "\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    annotations = []\n",
    "    ids  = [class_id for _, _, confidence, class_id,_ in detections]\n",
    "    for i,box in enumerate(boxes):\n",
    "        result = torch.from_numpy(box) * torch.Tensor([w, h, w, h])\n",
    "        annotations.append(Bbox(result[0], result[1], result[2], result[3], label=ids[i]))\n",
    "    \n",
    "    results.append(\n",
    "        DatasetItem(\n",
    "            id=image_name.split(\".\")[0],\n",
    "            media=Image.from_file(path=image_path),\n",
    "            annotations=annotations\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        name = image_name.split(\"/\")[-1]\n",
    "        \n",
    "        PIL.Image.fromarray(annotated_frame).save('/home/jupyter/datasphere/project/GroundingDINO/coco_export.json/images' + \"/\" + name)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "dataset = Dataset.from_iterable(results,categories = CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfd9bf-db75-4002-9614-2cc9ace15994",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.export(\"./coco_export.json\",format=\"coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b29c2-c99f-4881-8450-ae700ec84fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "coco_file = \"/home/jupyter/datasphere/project/GroundingDINO/coco_export.json/annotations/instances_default.json\" \n",
    "def convert_coco_to_yolov8(coco_file):\n",
    "    with open(coco_file) as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "        images = coco['images']\n",
    "        annotations = coco['annotations'] \n",
    "        categories = {cat['id']: cat['name'] for cat in coco['categories']}\n",
    "        #print(categories)\n",
    "        \n",
    "\n",
    "        os.makedirs('yolov8_labels', exist_ok=True)\n",
    "\n",
    "        for image in tqdm(images, desc='Converting images'):\n",
    "            image_id = image['id']\n",
    "            filename = image['file_name']\n",
    "            label_filename = (filename.split('.jpg')[0]).split('/')[-1]\n",
    "            \n",
    "            label_path = os.path.join('yolov8_labels', f'{label_filename}.txt')\n",
    "\n",
    "            with open(label_path, 'w') as f:\n",
    "                for ann in annotations:\n",
    "                    \n",
    "                    if ann['image_id'] != image_id:\n",
    "                        continue\n",
    "                    #print(ann)\n",
    "                    img_width = image['width']\n",
    "                    img_height = image['height']\n",
    "                    #print(img_width)\n",
    "                    #print(f\"Widht={img_width},height={img_height}\")\n",
    "                    label_id = ann['category_id']\n",
    "                    #print(label_id)\n",
    "                    label = categories[label_id]\n",
    "\n",
    "                    x1, y1, w, h = ann['bbox']\n",
    "                    \n",
    "                    x1 = x1/img_width\n",
    "                    y1 = y1/img_height\n",
    "                    w = w/img_width\n",
    "                    h = h/img_height\n",
    "                    #print(x1, '  ', y1,'  ', w, \"  \", h)\n",
    "                    \n",
    "                    x_center=((2*x1+w)/(2*img_width))\n",
    "                    y_center=((2*y1+h)/(2*img_height))\n",
    "                    w_box=w/img_width\n",
    "                    h_box=h/img_height\n",
    "                    \n",
    "                    if (x_center>=1) or (y_center>=1):\n",
    "                        break\n",
    "                    \n",
    "                    segmentation_points_str = '{:f} {:f} {:f} {:f}'.format(x_center,y_center,w_box,h_box)\n",
    "                    #print(segmentation_points_str)\n",
    "\n",
    "                    line = '{} {}'.format(label_id, segmentation_points_str)\n",
    "                    #print(line)\n",
    "                    \n",
    "                    f.write(line + '\\n')\n",
    "                \n",
    "convert_coco_to_yolov8(coco_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
